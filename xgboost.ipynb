{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import xgboost as xgb\n",
    "import optuna\n",
    "import seaborn as sns\n",
    "\n",
    "from utils import load_data, transform_dataset\n",
    "from dataset import encode_labels, decode_labels, labels_encoding\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = transform_dataset(load_data('train'))\n",
    "train_data = encode_labels(train_data)\n",
    "val_data = transform_dataset(load_data('val'))\n",
    "val_data = encode_labels(val_data)\n",
    "test_data = transform_dataset(load_data('test'))\n",
    "test_data = encode_labels(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(train_data[\"text\"].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(smooth_idf=True, norm='l2', sublinear_tf=True)\n",
    "tfidf.fit(train_data['text'])\n",
    "train_data_tfidf = tfidf.transform(train_data['text'])\n",
    "train_data_dmatrix = xgb.DMatrix(data=train_data_tfidf, label=train_data['label'])\n",
    "val_data_tfidf = tfidf.transform(val_data['text'])\n",
    "val_data_dmatrix = xgb.DMatrix(data=val_data_tfidf, label=val_data['label'])\n",
    "test_data_tfidf = tfidf.transform(test_data['text'])\n",
    "test_data_dmatrix = xgb.DMatrix(data=test_data_tfidf, label=test_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:42,382]\u001b[0m A new study created in memory with name: no-name-6e9c704d-032e-48c5-9bef-c32f5a4b3565\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72093\n",
      "[1]\tValidation-mlogloss:1.65669\n",
      "[2]\tValidation-mlogloss:1.60422\n",
      "[3]\tValidation-mlogloss:1.55391\n",
      "[4]\tValidation-mlogloss:1.51077\n",
      "[5]\tValidation-mlogloss:1.46769\n",
      "[6]\tValidation-mlogloss:1.42895\n",
      "[7]\tValidation-mlogloss:1.39569\n",
      "[8]\tValidation-mlogloss:1.36715\n",
      "[9]\tValidation-mlogloss:1.33897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:43,531]\u001b[0m Trial 0 finished with value: 0.7425 and parameters: {'eta': 0.1162617923294311, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.7476342598853876, 'colsample_bytree': 0.8988453085197287, 'alpha': 0.17563733063598796, 'lambda': 0.20013234136186542, 'gamma': 0.4198017056630555, 'n_estimators': 479}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.78580\n",
      "[1]\tValidation-mlogloss:1.77968\n",
      "[2]\tValidation-mlogloss:1.77400\n",
      "[3]\tValidation-mlogloss:1.76852\n",
      "[4]\tValidation-mlogloss:1.76273\n",
      "[5]\tValidation-mlogloss:1.75724\n",
      "[6]\tValidation-mlogloss:1.75154\n",
      "[7]\tValidation-mlogloss:1.74647\n",
      "[8]\tValidation-mlogloss:1.74134\n",
      "[9]\tValidation-mlogloss:1.73616\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:43,995]\u001b[0m Trial 1 finished with value: 0.471 and parameters: {'eta': 0.015257922806009096, 'max_depth': 3, 'min_child_weight': 8, 'subsample': 0.5076611444600055, 'colsample_bytree': 0.9069644420128898, 'alpha': 0.32942504980953, 'lambda': 0.6038086672948755, 'gamma': 0.4192123672615268, 'n_estimators': 941}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71260\n",
      "[1]\tValidation-mlogloss:1.64170\n",
      "[2]\tValidation-mlogloss:1.58306\n",
      "[3]\tValidation-mlogloss:1.52995\n",
      "[4]\tValidation-mlogloss:1.48712\n",
      "[5]\tValidation-mlogloss:1.44813\n",
      "[6]\tValidation-mlogloss:1.41263\n",
      "[7]\tValidation-mlogloss:1.38497\n",
      "[8]\tValidation-mlogloss:1.36013\n",
      "[9]\tValidation-mlogloss:1.33312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:44,542]\u001b[0m Trial 2 finished with value: 0.586 and parameters: {'eta': 0.198735807046039, 'max_depth': 4, 'min_child_weight': 7, 'subsample': 0.8711295969055213, 'colsample_bytree': 0.5755474752478069, 'alpha': 0.7299180068882313, 'lambda': 0.6052569148297413, 'gamma': 0.18013576834295453, 'n_estimators': 110}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.77897\n",
      "[1]\tValidation-mlogloss:1.76646\n",
      "[2]\tValidation-mlogloss:1.75462\n",
      "[3]\tValidation-mlogloss:1.74251\n",
      "[4]\tValidation-mlogloss:1.73113\n",
      "[5]\tValidation-mlogloss:1.71972\n",
      "[6]\tValidation-mlogloss:1.70815\n",
      "[7]\tValidation-mlogloss:1.69793\n",
      "[8]\tValidation-mlogloss:1.68791\n",
      "[9]\tValidation-mlogloss:1.67806\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:45,810]\u001b[0m Trial 3 finished with value: 0.651 and parameters: {'eta': 0.018548536094736112, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.7632408723717194, 'colsample_bytree': 0.8383206838695786, 'alpha': 0.564905800898265, 'lambda': 0.3186452653601364, 'gamma': 0.01077513468759117, 'n_estimators': 798}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:45] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.74737\n",
      "[1]\tValidation-mlogloss:1.70438\n",
      "[2]\tValidation-mlogloss:1.66697\n",
      "[3]\tValidation-mlogloss:1.62712\n",
      "[4]\tValidation-mlogloss:1.59570\n",
      "[5]\tValidation-mlogloss:1.56507\n",
      "[6]\tValidation-mlogloss:1.53700\n",
      "[7]\tValidation-mlogloss:1.51187\n",
      "[8]\tValidation-mlogloss:1.48584\n",
      "[9]\tValidation-mlogloss:1.46405\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:46,486]\u001b[0m Trial 4 finished with value: 0.629 and parameters: {'eta': 0.09036732399925926, 'max_depth': 6, 'min_child_weight': 8, 'subsample': 0.9736042710252396, 'colsample_bytree': 0.5958064328006725, 'alpha': 0.12862245222818214, 'lambda': 0.33536238355865733, 'gamma': 0.6644535547315067, 'n_estimators': 197}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.78504\n",
      "[1]\tValidation-mlogloss:1.77816\n",
      "[2]\tValidation-mlogloss:1.77148\n",
      "[3]\tValidation-mlogloss:1.76494\n",
      "[4]\tValidation-mlogloss:1.75874\n",
      "[5]\tValidation-mlogloss:1.75252\n",
      "[6]\tValidation-mlogloss:1.74596\n",
      "[7]\tValidation-mlogloss:1.74021\n",
      "[8]\tValidation-mlogloss:1.73429\n",
      "[9]\tValidation-mlogloss:1.72860\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:47,064]\u001b[0m Trial 5 finished with value: 0.5055 and parameters: {'eta': 0.015697474769700202, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.5715958827013291, 'colsample_bytree': 0.7757072799284903, 'alpha': 0.6074003673046215, 'lambda': 0.4909749736126978, 'gamma': 0.5832814704434475, 'n_estimators': 300}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71357\n",
      "[1]\tValidation-mlogloss:1.64487\n",
      "[2]\tValidation-mlogloss:1.58711\n",
      "[3]\tValidation-mlogloss:1.53330\n",
      "[4]\tValidation-mlogloss:1.48717\n",
      "[5]\tValidation-mlogloss:1.44925\n",
      "[6]\tValidation-mlogloss:1.41301\n",
      "[7]\tValidation-mlogloss:1.38240\n",
      "[8]\tValidation-mlogloss:1.35346\n",
      "[9]\tValidation-mlogloss:1.32642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:47,798]\u001b[0m Trial 6 finished with value: 0.6585 and parameters: {'eta': 0.1692674468917128, 'max_depth': 5, 'min_child_weight': 8, 'subsample': 0.9779202829129642, 'colsample_bytree': 0.8113660438502646, 'alpha': 0.6849222478411907, 'lambda': 0.22629802561771029, 'gamma': 0.03819430869145313, 'n_estimators': 152}. Best is trial 0 with value: 0.7425.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68168\n",
      "[1]\tValidation-mlogloss:1.58429\n",
      "[2]\tValidation-mlogloss:1.50758\n",
      "[3]\tValidation-mlogloss:1.43895\n",
      "[4]\tValidation-mlogloss:1.38390\n",
      "[5]\tValidation-mlogloss:1.32928\n",
      "[6]\tValidation-mlogloss:1.28351\n",
      "[7]\tValidation-mlogloss:1.24658\n",
      "[8]\tValidation-mlogloss:1.21080\n",
      "[9]\tValidation-mlogloss:1.18023\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:48,870]\u001b[0m Trial 7 finished with value: 0.776 and parameters: {'eta': 0.19408654922036278, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.961734962989798, 'colsample_bytree': 0.6654014752861952, 'alpha': 0.6536481672988779, 'lambda': 0.018884404861347015, 'gamma': 0.7721091417112499, 'n_estimators': 100}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.78448\n",
      "[1]\tValidation-mlogloss:1.77735\n",
      "[2]\tValidation-mlogloss:1.77020\n",
      "[3]\tValidation-mlogloss:1.76291\n",
      "[4]\tValidation-mlogloss:1.75627\n",
      "[5]\tValidation-mlogloss:1.74983\n",
      "[6]\tValidation-mlogloss:1.74316\n",
      "[7]\tValidation-mlogloss:1.73689\n",
      "[8]\tValidation-mlogloss:1.73078\n",
      "[9]\tValidation-mlogloss:1.72453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:49,525]\u001b[0m Trial 8 finished with value: 0.5145 and parameters: {'eta': 0.015109965137955856, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.9249541660995426, 'colsample_bytree': 0.6203334858244771, 'alpha': 0.8015692058580874, 'lambda': 0.33387116448094656, 'gamma': 0.4035359467944435, 'n_estimators': 580}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.77966\n",
      "[1]\tValidation-mlogloss:1.76755\n",
      "[2]\tValidation-mlogloss:1.75572\n",
      "[3]\tValidation-mlogloss:1.74369\n",
      "[4]\tValidation-mlogloss:1.73315\n",
      "[5]\tValidation-mlogloss:1.72215\n",
      "[6]\tValidation-mlogloss:1.71111\n",
      "[7]\tValidation-mlogloss:1.70093\n",
      "[8]\tValidation-mlogloss:1.69051\n",
      "[9]\tValidation-mlogloss:1.68043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:50,210]\u001b[0m Trial 9 finished with value: 0.5295 and parameters: {'eta': 0.02640754506666095, 'max_depth': 5, 'min_child_weight': 10, 'subsample': 0.9358215459946455, 'colsample_bytree': 0.7424936412779422, 'alpha': 0.6326949395776973, 'lambda': 0.6034153699213631, 'gamma': 0.022426310197030785, 'n_estimators': 240}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.76168\n",
      "[1]\tValidation-mlogloss:1.73164\n",
      "[2]\tValidation-mlogloss:1.70642\n",
      "[3]\tValidation-mlogloss:1.67932\n",
      "[4]\tValidation-mlogloss:1.65572\n",
      "[5]\tValidation-mlogloss:1.63257\n",
      "[6]\tValidation-mlogloss:1.60991\n",
      "[7]\tValidation-mlogloss:1.59040\n",
      "[8]\tValidation-mlogloss:1.57136\n",
      "[9]\tValidation-mlogloss:1.55268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:51,075]\u001b[0m Trial 10 finished with value: 0.6415 and parameters: {'eta': 0.05225908399490967, 'max_depth': 8, 'min_child_weight': 1, 'subsample': 0.7979653675018715, 'colsample_bytree': 0.5023466861189363, 'alpha': 0.9169467494997509, 'lambda': 0.010974149619664642, 'gamma': 0.9564714001575112, 'n_estimators': 440}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72629\n",
      "[1]\tValidation-mlogloss:1.66392\n",
      "[2]\tValidation-mlogloss:1.61364\n",
      "[3]\tValidation-mlogloss:1.56753\n",
      "[4]\tValidation-mlogloss:1.52552\n",
      "[5]\tValidation-mlogloss:1.48498\n",
      "[6]\tValidation-mlogloss:1.44754\n",
      "[7]\tValidation-mlogloss:1.41452\n",
      "[8]\tValidation-mlogloss:1.38656\n",
      "[9]\tValidation-mlogloss:1.36028\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:52,309]\u001b[0m Trial 11 finished with value: 0.7245 and parameters: {'eta': 0.10827730291228575, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.6585876705504348, 'colsample_bytree': 0.9595778779112818, 'alpha': 0.36573802230426067, 'lambda': 0.0324713157367848, 'gamma': 0.7960495818115826, 'n_estimators': 631}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:52] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.73579\n",
      "[1]\tValidation-mlogloss:1.68513\n",
      "[2]\tValidation-mlogloss:1.63860\n",
      "[3]\tValidation-mlogloss:1.59634\n",
      "[4]\tValidation-mlogloss:1.55892\n",
      "[5]\tValidation-mlogloss:1.52163\n",
      "[6]\tValidation-mlogloss:1.48797\n",
      "[7]\tValidation-mlogloss:1.46097\n",
      "[8]\tValidation-mlogloss:1.43421\n",
      "[9]\tValidation-mlogloss:1.40816\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:53,296]\u001b[0m Trial 12 finished with value: 0.6885 and parameters: {'eta': 0.0964739893040461, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.7048635148070114, 'colsample_bytree': 0.7015816627374084, 'alpha': 0.054251533860408374, 'lambda': 0.9008664343389096, 'gamma': 0.7814976503338493, 'n_estimators': 413}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.75553\n",
      "[1]\tValidation-mlogloss:1.72027\n",
      "[2]\tValidation-mlogloss:1.68854\n",
      "[3]\tValidation-mlogloss:1.65843\n",
      "[4]\tValidation-mlogloss:1.63098\n",
      "[5]\tValidation-mlogloss:1.60247\n",
      "[6]\tValidation-mlogloss:1.57646\n",
      "[7]\tValidation-mlogloss:1.55378\n",
      "[8]\tValidation-mlogloss:1.53253\n",
      "[9]\tValidation-mlogloss:1.51061\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:54,521]\u001b[0m Trial 13 finished with value: 0.6935 and parameters: {'eta': 0.05418751424880949, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8413424520230324, 'colsample_bytree': 0.6745575420363169, 'alpha': 0.394258817715311, 'lambda': 0.1493164636916121, 'gamma': 0.31496277136477074, 'n_estimators': 754}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72194\n",
      "[1]\tValidation-mlogloss:1.65739\n",
      "[2]\tValidation-mlogloss:1.60305\n",
      "[3]\tValidation-mlogloss:1.55619\n",
      "[4]\tValidation-mlogloss:1.51440\n",
      "[5]\tValidation-mlogloss:1.47137\n",
      "[6]\tValidation-mlogloss:1.43461\n",
      "[7]\tValidation-mlogloss:1.40151\n",
      "[8]\tValidation-mlogloss:1.37267\n",
      "[9]\tValidation-mlogloss:1.34588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:55,522]\u001b[0m Trial 14 finished with value: 0.7225 and parameters: {'eta': 0.12435169055913357, 'max_depth': 7, 'min_child_weight': 5, 'subsample': 0.6911178622653441, 'colsample_bytree': 0.8657921104391036, 'alpha': 0.19341351108514143, 'lambda': 0.14346385361122763, 'gamma': 0.9979518588335414, 'n_estimators': 349}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.74743\n",
      "[1]\tValidation-mlogloss:1.70460\n",
      "[2]\tValidation-mlogloss:1.66650\n",
      "[3]\tValidation-mlogloss:1.63154\n",
      "[4]\tValidation-mlogloss:1.59976\n",
      "[5]\tValidation-mlogloss:1.56829\n",
      "[6]\tValidation-mlogloss:1.53912\n",
      "[7]\tValidation-mlogloss:1.51231\n",
      "[8]\tValidation-mlogloss:1.48838\n",
      "[9]\tValidation-mlogloss:1.46536\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:56,920]\u001b[0m Trial 15 finished with value: 0.6855 and parameters: {'eta': 0.07102462467700153, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.6331314906733553, 'colsample_bytree': 0.9837279772801419, 'alpha': 0.2408254547105042, 'lambda': 0.9523140776243226, 'gamma': 0.5676060186037255, 'n_estimators': 461}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:56] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71278\n",
      "[1]\tValidation-mlogloss:1.63967\n",
      "[2]\tValidation-mlogloss:1.57883\n",
      "[3]\tValidation-mlogloss:1.52933\n",
      "[4]\tValidation-mlogloss:1.48398\n",
      "[5]\tValidation-mlogloss:1.43917\n",
      "[6]\tValidation-mlogloss:1.40320\n",
      "[7]\tValidation-mlogloss:1.36769\n",
      "[8]\tValidation-mlogloss:1.33800\n",
      "[9]\tValidation-mlogloss:1.31256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:58,013]\u001b[0m Trial 16 finished with value: 0.731 and parameters: {'eta': 0.14110392720824838, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.8299528624678629, 'colsample_bytree': 0.9128735792857054, 'alpha': 0.4690390654284369, 'lambda': 0.09725356454169082, 'gamma': 0.749421271216515, 'n_estimators': 686}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.76998\n",
      "[1]\tValidation-mlogloss:1.74916\n",
      "[2]\tValidation-mlogloss:1.72944\n",
      "[3]\tValidation-mlogloss:1.71008\n",
      "[4]\tValidation-mlogloss:1.69290\n",
      "[5]\tValidation-mlogloss:1.67430\n",
      "[6]\tValidation-mlogloss:1.65707\n",
      "[7]\tValidation-mlogloss:1.64168\n",
      "[8]\tValidation-mlogloss:1.62675\n",
      "[9]\tValidation-mlogloss:1.61124\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:22:59,061]\u001b[0m Trial 17 finished with value: 0.661 and parameters: {'eta': 0.03346096499382542, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.7431685447613966, 'colsample_bytree': 0.6635530413431876, 'alpha': 0.02194283602458358, 'lambda': 0.21971079878825475, 'gamma': 0.2904238264249279, 'n_estimators': 996}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:22:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.74476\n",
      "[1]\tValidation-mlogloss:1.69910\n",
      "[2]\tValidation-mlogloss:1.66065\n",
      "[3]\tValidation-mlogloss:1.62257\n",
      "[4]\tValidation-mlogloss:1.58847\n",
      "[5]\tValidation-mlogloss:1.55407\n",
      "[6]\tValidation-mlogloss:1.52536\n",
      "[7]\tValidation-mlogloss:1.49855\n",
      "[8]\tValidation-mlogloss:1.47380\n",
      "[9]\tValidation-mlogloss:1.44796\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:00,372]\u001b[0m Trial 18 finished with value: 0.696 and parameters: {'eta': 0.07664615019101549, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.8917139470121205, 'colsample_bytree': 0.7341843856387658, 'alpha': 0.8790413154430691, 'lambda': 0.48425617153714345, 'gamma': 0.8881568976365157, 'n_estimators': 487}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71347\n",
      "[1]\tValidation-mlogloss:1.64374\n",
      "[2]\tValidation-mlogloss:1.58693\n",
      "[3]\tValidation-mlogloss:1.53212\n",
      "[4]\tValidation-mlogloss:1.48718\n",
      "[5]\tValidation-mlogloss:1.44268\n",
      "[6]\tValidation-mlogloss:1.40508\n",
      "[7]\tValidation-mlogloss:1.37273\n",
      "[8]\tValidation-mlogloss:1.34256\n",
      "[9]\tValidation-mlogloss:1.31412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:01,137]\u001b[0m Trial 19 finished with value: 0.712 and parameters: {'eta': 0.14949834537958895, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.7749623875941277, 'colsample_bytree': 0.5228278307394002, 'alpha': 0.4684178325172019, 'lambda': 0.8143589031759266, 'gamma': 0.5009986635510615, 'n_estimators': 304}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69778\n",
      "[1]\tValidation-mlogloss:1.61550\n",
      "[2]\tValidation-mlogloss:1.54608\n",
      "[3]\tValidation-mlogloss:1.48790\n",
      "[4]\tValidation-mlogloss:1.43697\n",
      "[5]\tValidation-mlogloss:1.39131\n",
      "[6]\tValidation-mlogloss:1.34864\n",
      "[7]\tValidation-mlogloss:1.31368\n",
      "[8]\tValidation-mlogloss:1.28183\n",
      "[9]\tValidation-mlogloss:1.25646\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:02,066]\u001b[0m Trial 20 finished with value: 0.686 and parameters: {'eta': 0.18841446387187624, 'max_depth': 6, 'min_child_weight': 2, 'subsample': 0.6015682782325752, 'colsample_bytree': 0.7881357246488017, 'alpha': 0.26065870092848664, 'lambda': 0.22505713122136692, 'gamma': 0.6416879452643658, 'n_estimators': 839}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70833\n",
      "[1]\tValidation-mlogloss:1.63423\n",
      "[2]\tValidation-mlogloss:1.57199\n",
      "[3]\tValidation-mlogloss:1.52061\n",
      "[4]\tValidation-mlogloss:1.47412\n",
      "[5]\tValidation-mlogloss:1.42797\n",
      "[6]\tValidation-mlogloss:1.39204\n",
      "[7]\tValidation-mlogloss:1.35545\n",
      "[8]\tValidation-mlogloss:1.32491\n",
      "[9]\tValidation-mlogloss:1.29934\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:03,280]\u001b[0m Trial 21 finished with value: 0.7275 and parameters: {'eta': 0.14733033572734788, 'max_depth': 7, 'min_child_weight': 6, 'subsample': 0.8212887126521815, 'colsample_bytree': 0.9219826649021332, 'alpha': 0.483286131129138, 'lambda': 0.0884576804803142, 'gamma': 0.7609636311400152, 'n_estimators': 672}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71673\n",
      "[1]\tValidation-mlogloss:1.64568\n",
      "[2]\tValidation-mlogloss:1.58671\n",
      "[3]\tValidation-mlogloss:1.53675\n",
      "[4]\tValidation-mlogloss:1.49216\n",
      "[5]\tValidation-mlogloss:1.44825\n",
      "[6]\tValidation-mlogloss:1.41017\n",
      "[7]\tValidation-mlogloss:1.37616\n",
      "[8]\tValidation-mlogloss:1.34611\n",
      "[9]\tValidation-mlogloss:1.31711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:04,525]\u001b[0m Trial 22 finished with value: 0.74 and parameters: {'eta': 0.12720001992305058, 'max_depth': 8, 'min_child_weight': 6, 'subsample': 0.8563321375519386, 'colsample_bytree': 0.8849903785277844, 'alpha': 0.7744226302522588, 'lambda': 0.09073366027385843, 'gamma': 0.7025288816174237, 'n_estimators': 731}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72676\n",
      "[1]\tValidation-mlogloss:1.66365\n",
      "[2]\tValidation-mlogloss:1.61053\n",
      "[3]\tValidation-mlogloss:1.56472\n",
      "[4]\tValidation-mlogloss:1.52153\n",
      "[5]\tValidation-mlogloss:1.48194\n",
      "[6]\tValidation-mlogloss:1.44592\n",
      "[7]\tValidation-mlogloss:1.41248\n",
      "[8]\tValidation-mlogloss:1.38293\n",
      "[9]\tValidation-mlogloss:1.35525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:05,958]\u001b[0m Trial 23 finished with value: 0.7345 and parameters: {'eta': 0.11145677614448987, 'max_depth': 8, 'min_child_weight': 5, 'subsample': 0.8950622355278577, 'colsample_bytree': 0.8898288509285819, 'alpha': 0.8020388299311502, 'lambda': 0.02044839071461163, 'gamma': 0.8706578268461997, 'n_estimators': 580}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:05] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.75133\n",
      "[1]\tValidation-mlogloss:1.71305\n",
      "[2]\tValidation-mlogloss:1.67751\n",
      "[3]\tValidation-mlogloss:1.64313\n",
      "[4]\tValidation-mlogloss:1.61309\n",
      "[5]\tValidation-mlogloss:1.58306\n",
      "[6]\tValidation-mlogloss:1.55519\n",
      "[7]\tValidation-mlogloss:1.52959\n",
      "[8]\tValidation-mlogloss:1.50539\n",
      "[9]\tValidation-mlogloss:1.48257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:07,347]\u001b[0m Trial 24 finished with value: 0.699 and parameters: {'eta': 0.06477792111462316, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.9372905712799382, 'colsample_bytree': 0.8328339402137886, 'alpha': 0.9709338643657293, 'lambda': 0.4022596157686127, 'gamma': 0.640864614018523, 'n_estimators': 873}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.76903\n",
      "[1]\tValidation-mlogloss:1.74817\n",
      "[2]\tValidation-mlogloss:1.72724\n",
      "[3]\tValidation-mlogloss:1.70761\n",
      "[4]\tValidation-mlogloss:1.68773\n",
      "[5]\tValidation-mlogloss:1.67012\n",
      "[6]\tValidation-mlogloss:1.65161\n",
      "[7]\tValidation-mlogloss:1.63390\n",
      "[8]\tValidation-mlogloss:1.61831\n",
      "[9]\tValidation-mlogloss:1.60267\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:08,906]\u001b[0m Trial 25 finished with value: 0.6385 and parameters: {'eta': 0.037383361426348204, 'max_depth': 8, 'min_child_weight': 10, 'subsample': 0.99910084147901, 'colsample_bytree': 0.9984417972948464, 'alpha': 0.7664959353571915, 'lambda': 0.1693066111488073, 'gamma': 0.49027820316395637, 'n_estimators': 735}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.78413\n",
      "[1]\tValidation-mlogloss:1.77620\n",
      "[2]\tValidation-mlogloss:1.76885\n",
      "[3]\tValidation-mlogloss:1.76141\n",
      "[4]\tValidation-mlogloss:1.75416\n",
      "[5]\tValidation-mlogloss:1.74692\n",
      "[6]\tValidation-mlogloss:1.73966\n",
      "[7]\tValidation-mlogloss:1.73268\n",
      "[8]\tValidation-mlogloss:1.72610\n",
      "[9]\tValidation-mlogloss:1.71958\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:10,461]\u001b[0m Trial 26 finished with value: 0.6265 and parameters: {'eta': 0.011083775500663022, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.7227903625307994, 'colsample_bytree': 0.9566896379393933, 'alpha': 0.5544483556383812, 'lambda': 0.08073919824691728, 'gamma': 0.885808972564627, 'n_estimators': 533}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.75020\n",
      "[1]\tValidation-mlogloss:1.71085\n",
      "[2]\tValidation-mlogloss:1.67395\n",
      "[3]\tValidation-mlogloss:1.64155\n",
      "[4]\tValidation-mlogloss:1.61107\n",
      "[5]\tValidation-mlogloss:1.58112\n",
      "[6]\tValidation-mlogloss:1.55461\n",
      "[7]\tValidation-mlogloss:1.52990\n",
      "[8]\tValidation-mlogloss:1.50586\n",
      "[9]\tValidation-mlogloss:1.48480\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:11,458]\u001b[0m Trial 27 finished with value: 0.626 and parameters: {'eta': 0.08066352330247777, 'max_depth': 6, 'min_child_weight': 6, 'subsample': 0.8604180897659702, 'colsample_bytree': 0.8605440998963324, 'alpha': 0.6705142661499107, 'lambda': 0.25111749222292806, 'gamma': 0.7195351564449537, 'n_estimators': 384}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71653\n",
      "[1]\tValidation-mlogloss:1.64700\n",
      "[2]\tValidation-mlogloss:1.59109\n",
      "[3]\tValidation-mlogloss:1.53874\n",
      "[4]\tValidation-mlogloss:1.49262\n",
      "[5]\tValidation-mlogloss:1.44600\n",
      "[6]\tValidation-mlogloss:1.40757\n",
      "[7]\tValidation-mlogloss:1.37263\n",
      "[8]\tValidation-mlogloss:1.34237\n",
      "[9]\tValidation-mlogloss:1.31197\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:12,805]\u001b[0m Trial 28 finished with value: 0.7445 and parameters: {'eta': 0.12137881362946726, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.801308488027045, 'colsample_bytree': 0.7121465602879032, 'alpha': 0.8478200502851275, 'lambda': 0.0034457488833474215, 'gamma': 0.5398726228809748, 'n_estimators': 234}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:12] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69045\n",
      "[1]\tValidation-mlogloss:1.60036\n",
      "[2]\tValidation-mlogloss:1.52559\n",
      "[3]\tValidation-mlogloss:1.46155\n",
      "[4]\tValidation-mlogloss:1.40825\n",
      "[5]\tValidation-mlogloss:1.35734\n",
      "[6]\tValidation-mlogloss:1.31184\n",
      "[7]\tValidation-mlogloss:1.27188\n",
      "[8]\tValidation-mlogloss:1.23549\n",
      "[9]\tValidation-mlogloss:1.20445\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:13,869]\u001b[0m Trial 29 finished with value: 0.763 and parameters: {'eta': 0.16885712906664727, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.5179040030149571, 'colsample_bytree': 0.6469488184416304, 'alpha': 0.8740656453749063, 'lambda': 0.01721910264061992, 'gamma': 0.3906314460890936, 'n_estimators': 236}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69208\n",
      "[1]\tValidation-mlogloss:1.60456\n",
      "[2]\tValidation-mlogloss:1.53187\n",
      "[3]\tValidation-mlogloss:1.46894\n",
      "[4]\tValidation-mlogloss:1.41668\n",
      "[5]\tValidation-mlogloss:1.36538\n",
      "[6]\tValidation-mlogloss:1.32067\n",
      "[7]\tValidation-mlogloss:1.28153\n",
      "[8]\tValidation-mlogloss:1.24466\n",
      "[9]\tValidation-mlogloss:1.21467\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:14,956]\u001b[0m Trial 30 finished with value: 0.759 and parameters: {'eta': 0.1647278369144677, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.5116770760406958, 'colsample_bytree': 0.6367696088620777, 'alpha': 0.9976674042756438, 'lambda': 0.0019569266488037437, 'gamma': 0.3105517174310175, 'n_estimators': 227}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69400\n",
      "[1]\tValidation-mlogloss:1.60881\n",
      "[2]\tValidation-mlogloss:1.53761\n",
      "[3]\tValidation-mlogloss:1.47562\n",
      "[4]\tValidation-mlogloss:1.42379\n",
      "[5]\tValidation-mlogloss:1.37323\n",
      "[6]\tValidation-mlogloss:1.32934\n",
      "[7]\tValidation-mlogloss:1.28970\n",
      "[8]\tValidation-mlogloss:1.25336\n",
      "[9]\tValidation-mlogloss:1.22315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:16,669]\u001b[0m Trial 31 finished with value: 0.755 and parameters: {'eta': 0.16174137303939637, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.5153489168723819, 'colsample_bytree': 0.636653796771287, 'alpha': 0.9886665891819646, 'lambda': 0.018300850873315937, 'gamma': 0.2718381938625025, 'n_estimators': 235}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:16] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68498\n",
      "[1]\tValidation-mlogloss:1.59287\n",
      "[2]\tValidation-mlogloss:1.51378\n",
      "[3]\tValidation-mlogloss:1.45002\n",
      "[4]\tValidation-mlogloss:1.39618\n",
      "[5]\tValidation-mlogloss:1.34253\n",
      "[6]\tValidation-mlogloss:1.29535\n",
      "[7]\tValidation-mlogloss:1.25570\n",
      "[8]\tValidation-mlogloss:1.21861\n",
      "[9]\tValidation-mlogloss:1.18596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:18,769]\u001b[0m Trial 32 finished with value: 0.769 and parameters: {'eta': 0.1687203242876787, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5147067752805318, 'colsample_bytree': 0.6442784529408494, 'alpha': 0.9993962699198665, 'lambda': 0.0750688015439749, 'gamma': 0.22640758500087188, 'n_estimators': 100}. Best is trial 7 with value: 0.776.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67229\n",
      "[1]\tValidation-mlogloss:1.56620\n",
      "[2]\tValidation-mlogloss:1.48106\n",
      "[3]\tValidation-mlogloss:1.40836\n",
      "[4]\tValidation-mlogloss:1.34949\n",
      "[5]\tValidation-mlogloss:1.29291\n",
      "[6]\tValidation-mlogloss:1.24477\n",
      "[7]\tValidation-mlogloss:1.20598\n",
      "[8]\tValidation-mlogloss:1.16460\n",
      "[9]\tValidation-mlogloss:1.13010\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:20,118]\u001b[0m Trial 33 finished with value: 0.78 and parameters: {'eta': 0.19948443937301752, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5471886724476728, 'colsample_bytree': 0.5794878755912557, 'alpha': 0.9411020382735839, 'lambda': 0.11148245996905629, 'gamma': 0.16116338828579613, 'n_estimators': 119}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67638\n",
      "[1]\tValidation-mlogloss:1.57405\n",
      "[2]\tValidation-mlogloss:1.49574\n",
      "[3]\tValidation-mlogloss:1.42374\n",
      "[4]\tValidation-mlogloss:1.36597\n",
      "[5]\tValidation-mlogloss:1.31080\n",
      "[6]\tValidation-mlogloss:1.26224\n",
      "[7]\tValidation-mlogloss:1.22195\n",
      "[8]\tValidation-mlogloss:1.18301\n",
      "[9]\tValidation-mlogloss:1.14954\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:21,193]\u001b[0m Trial 34 finished with value: 0.7705 and parameters: {'eta': 0.19023545828137964, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5534576446445805, 'colsample_bytree': 0.5669708318831631, 'alpha': 0.9247279538583759, 'lambda': 0.13436274050217992, 'gamma': 0.14638162703218024, 'n_estimators': 103}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67494\n",
      "[1]\tValidation-mlogloss:1.56863\n",
      "[2]\tValidation-mlogloss:1.48492\n",
      "[3]\tValidation-mlogloss:1.41316\n",
      "[4]\tValidation-mlogloss:1.35203\n",
      "[5]\tValidation-mlogloss:1.29538\n",
      "[6]\tValidation-mlogloss:1.24614\n",
      "[7]\tValidation-mlogloss:1.20567\n",
      "[8]\tValidation-mlogloss:1.16707\n",
      "[9]\tValidation-mlogloss:1.13289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:22,838]\u001b[0m Trial 35 finished with value: 0.7725 and parameters: {'eta': 0.1980160355190156, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5641749386423037, 'colsample_bytree': 0.5703352012185271, 'alpha': 0.9400518012814981, 'lambda': 0.14811993197282813, 'gamma': 0.13038467721436214, 'n_estimators': 100}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:22] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.73300\n",
      "[1]\tValidation-mlogloss:1.67550\n",
      "[2]\tValidation-mlogloss:1.62612\n",
      "[3]\tValidation-mlogloss:1.58083\n",
      "[4]\tValidation-mlogloss:1.54171\n",
      "[5]\tValidation-mlogloss:1.50246\n",
      "[6]\tValidation-mlogloss:1.46601\n",
      "[7]\tValidation-mlogloss:1.43452\n",
      "[8]\tValidation-mlogloss:1.40210\n",
      "[9]\tValidation-mlogloss:1.37540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:24,056]\u001b[0m Trial 36 finished with value: 0.721 and parameters: {'eta': 0.09732786274093097, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.561478072261042, 'colsample_bytree': 0.5700246280747123, 'alpha': 0.9255270005992189, 'lambda': 0.2706141733301546, 'gamma': 0.12873948320889425, 'n_estimators': 151}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:24] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67398\n",
      "[1]\tValidation-mlogloss:1.57017\n",
      "[2]\tValidation-mlogloss:1.49110\n",
      "[3]\tValidation-mlogloss:1.41844\n",
      "[4]\tValidation-mlogloss:1.35751\n",
      "[5]\tValidation-mlogloss:1.30015\n",
      "[6]\tValidation-mlogloss:1.25118\n",
      "[7]\tValidation-mlogloss:1.21253\n",
      "[8]\tValidation-mlogloss:1.17320\n",
      "[9]\tValidation-mlogloss:1.13979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:25,217]\u001b[0m Trial 37 finished with value: 0.7655 and parameters: {'eta': 0.19913674611030294, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5570720880436597, 'colsample_bytree': 0.5645947216819187, 'alpha': 0.9284101530453643, 'lambda': 0.40719620946254603, 'gamma': 0.126997123284688, 'n_estimators': 158}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67458\n",
      "[1]\tValidation-mlogloss:1.56983\n",
      "[2]\tValidation-mlogloss:1.49026\n",
      "[3]\tValidation-mlogloss:1.41958\n",
      "[4]\tValidation-mlogloss:1.35911\n",
      "[5]\tValidation-mlogloss:1.30374\n",
      "[6]\tValidation-mlogloss:1.25539\n",
      "[7]\tValidation-mlogloss:1.21762\n",
      "[8]\tValidation-mlogloss:1.17978\n",
      "[9]\tValidation-mlogloss:1.14449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:26,391]\u001b[0m Trial 38 finished with value: 0.762 and parameters: {'eta': 0.19674655982598394, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.6173212862725302, 'colsample_bytree': 0.5359478281040184, 'alpha': 0.8415597657905272, 'lambda': 0.2911357645809409, 'gamma': 0.09944756264036997, 'n_estimators': 167}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71095\n",
      "[1]\tValidation-mlogloss:1.63638\n",
      "[2]\tValidation-mlogloss:1.57412\n",
      "[3]\tValidation-mlogloss:1.51719\n",
      "[4]\tValidation-mlogloss:1.46917\n",
      "[5]\tValidation-mlogloss:1.42341\n",
      "[6]\tValidation-mlogloss:1.38175\n",
      "[7]\tValidation-mlogloss:1.34644\n",
      "[8]\tValidation-mlogloss:1.31122\n",
      "[9]\tValidation-mlogloss:1.28018\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:27,574]\u001b[0m Trial 39 finished with value: 0.7535 and parameters: {'eta': 0.12942081837818645, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.586569853557223, 'colsample_bytree': 0.6022814387901264, 'alpha': 0.7201377790864945, 'lambda': 0.16702423376482253, 'gamma': 0.07468774809334397, 'n_estimators': 302}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:27] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70773\n",
      "[1]\tValidation-mlogloss:1.62737\n",
      "[2]\tValidation-mlogloss:1.56210\n",
      "[3]\tValidation-mlogloss:1.50504\n",
      "[4]\tValidation-mlogloss:1.45597\n",
      "[5]\tValidation-mlogloss:1.40901\n",
      "[6]\tValidation-mlogloss:1.36651\n",
      "[7]\tValidation-mlogloss:1.33047\n",
      "[8]\tValidation-mlogloss:1.29491\n",
      "[9]\tValidation-mlogloss:1.26312\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:28,966]\u001b[0m Trial 40 finished with value: 0.7495 and parameters: {'eta': 0.142149851671241, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.6440288801177713, 'colsample_bytree': 0.5910320419150846, 'alpha': 0.9310070476310667, 'lambda': 0.7237978498530613, 'gamma': 0.19339500467253756, 'n_estimators': 106}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72685\n",
      "[1]\tValidation-mlogloss:1.66909\n",
      "[2]\tValidation-mlogloss:1.62136\n",
      "[3]\tValidation-mlogloss:1.57194\n",
      "[4]\tValidation-mlogloss:1.53738\n",
      "[5]\tValidation-mlogloss:1.50378\n",
      "[6]\tValidation-mlogloss:1.47413\n",
      "[7]\tValidation-mlogloss:1.44976\n",
      "[8]\tValidation-mlogloss:1.42550\n",
      "[9]\tValidation-mlogloss:1.40229\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:29,457]\u001b[0m Trial 41 finished with value: 0.52 and parameters: {'eta': 0.1786920962432747, 'max_depth': 3, 'min_child_weight': 2, 'subsample': 0.542147826291441, 'colsample_bytree': 0.5426071630869654, 'alpha': 0.9561987931930208, 'lambda': 0.1184800258270682, 'gamma': 0.190547505446508, 'n_estimators': 103}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:29] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68424\n",
      "[1]\tValidation-mlogloss:1.58813\n",
      "[2]\tValidation-mlogloss:1.51130\n",
      "[3]\tValidation-mlogloss:1.44314\n",
      "[4]\tValidation-mlogloss:1.38922\n",
      "[5]\tValidation-mlogloss:1.33590\n",
      "[6]\tValidation-mlogloss:1.28978\n",
      "[7]\tValidation-mlogloss:1.25315\n",
      "[8]\tValidation-mlogloss:1.21293\n",
      "[9]\tValidation-mlogloss:1.17950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:30,576]\u001b[0m Trial 42 finished with value: 0.7735 and parameters: {'eta': 0.1722485985503463, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5372723123344489, 'colsample_bytree': 0.6039001306036654, 'alpha': 0.8814999787896883, 'lambda': 0.06253539544282176, 'gamma': 0.2320287808427131, 'n_estimators': 184}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67248\n",
      "[1]\tValidation-mlogloss:1.56787\n",
      "[2]\tValidation-mlogloss:1.48351\n",
      "[3]\tValidation-mlogloss:1.41130\n",
      "[4]\tValidation-mlogloss:1.35206\n",
      "[5]\tValidation-mlogloss:1.29670\n",
      "[6]\tValidation-mlogloss:1.24768\n",
      "[7]\tValidation-mlogloss:1.20736\n",
      "[8]\tValidation-mlogloss:1.16881\n",
      "[9]\tValidation-mlogloss:1.13385\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:31,745]\u001b[0m Trial 43 finished with value: 0.7685 and parameters: {'eta': 0.19609445522412577, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5815211049626338, 'colsample_bytree': 0.6121157055340694, 'alpha': 0.875932728027541, 'lambda': 0.2116964470458042, 'gamma': 0.14222775531895857, 'n_estimators': 174}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69779\n",
      "[1]\tValidation-mlogloss:1.61293\n",
      "[2]\tValidation-mlogloss:1.54667\n",
      "[3]\tValidation-mlogloss:1.48400\n",
      "[4]\tValidation-mlogloss:1.43104\n",
      "[5]\tValidation-mlogloss:1.38152\n",
      "[6]\tValidation-mlogloss:1.33735\n",
      "[7]\tValidation-mlogloss:1.30027\n",
      "[8]\tValidation-mlogloss:1.26292\n",
      "[9]\tValidation-mlogloss:1.22995\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:32,973]\u001b[0m Trial 44 finished with value: 0.7625 and parameters: {'eta': 0.15170406068595782, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5552162755942237, 'colsample_bytree': 0.5536146869678923, 'alpha': 0.8316161767340046, 'lambda': 0.1769594121977621, 'gamma': 0.3554512720495521, 'n_estimators': 197}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72747\n",
      "[1]\tValidation-mlogloss:1.66806\n",
      "[2]\tValidation-mlogloss:1.61758\n",
      "[3]\tValidation-mlogloss:1.57035\n",
      "[4]\tValidation-mlogloss:1.52862\n",
      "[5]\tValidation-mlogloss:1.48777\n",
      "[6]\tValidation-mlogloss:1.45207\n",
      "[7]\tValidation-mlogloss:1.42206\n",
      "[8]\tValidation-mlogloss:1.39005\n",
      "[9]\tValidation-mlogloss:1.36355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:33,916]\u001b[0m Trial 45 finished with value: 0.7155 and parameters: {'eta': 0.10656186372308675, 'max_depth': 9, 'min_child_weight': 1, 'subsample': 0.5387355884002236, 'colsample_bytree': 0.5072417975810348, 'alpha': 0.5885128306419902, 'lambda': 0.06071748648639545, 'gamma': 0.23997654454579143, 'n_estimators': 140}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70866\n",
      "[1]\tValidation-mlogloss:1.62986\n",
      "[2]\tValidation-mlogloss:1.56598\n",
      "[3]\tValidation-mlogloss:1.50839\n",
      "[4]\tValidation-mlogloss:1.45927\n",
      "[5]\tValidation-mlogloss:1.41391\n",
      "[6]\tValidation-mlogloss:1.37229\n",
      "[7]\tValidation-mlogloss:1.33708\n",
      "[8]\tValidation-mlogloss:1.30049\n",
      "[9]\tValidation-mlogloss:1.26833\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:35,126]\u001b[0m Trial 46 finished with value: 0.7495 and parameters: {'eta': 0.1340569398154594, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.609122882583872, 'colsample_bytree': 0.5859655081372361, 'alpha': 0.7109490472605864, 'lambda': 0.11812879652323346, 'gamma': 0.05131647154493897, 'n_estimators': 280}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:35] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68629\n",
      "[1]\tValidation-mlogloss:1.59073\n",
      "[2]\tValidation-mlogloss:1.51411\n",
      "[3]\tValidation-mlogloss:1.44977\n",
      "[4]\tValidation-mlogloss:1.39336\n",
      "[5]\tValidation-mlogloss:1.34187\n",
      "[6]\tValidation-mlogloss:1.29619\n",
      "[7]\tValidation-mlogloss:1.25787\n",
      "[8]\tValidation-mlogloss:1.22282\n",
      "[9]\tValidation-mlogloss:1.18996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:36,309]\u001b[0m Trial 47 finished with value: 0.7705 and parameters: {'eta': 0.17839601404453323, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.6725027070253029, 'colsample_bytree': 0.6917756514165494, 'alpha': 0.7603727660311663, 'lambda': 0.3230835035815032, 'gamma': 0.010645091789879074, 'n_estimators': 192}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69130\n",
      "[1]\tValidation-mlogloss:1.60070\n",
      "[2]\tValidation-mlogloss:1.52772\n",
      "[3]\tValidation-mlogloss:1.46642\n",
      "[4]\tValidation-mlogloss:1.41130\n",
      "[5]\tValidation-mlogloss:1.36061\n",
      "[6]\tValidation-mlogloss:1.31607\n",
      "[7]\tValidation-mlogloss:1.27897\n",
      "[8]\tValidation-mlogloss:1.24288\n",
      "[9]\tValidation-mlogloss:1.21160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:37,524]\u001b[0m Trial 48 finished with value: 0.7625 and parameters: {'eta': 0.16729628019355391, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.6701748795134079, 'colsample_bytree': 0.7047091896780531, 'alpha': 0.6606935240355594, 'lambda': 0.31447356558750844, 'gamma': 0.0026352953017252656, 'n_estimators': 344}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:37] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.77982\n",
      "[1]\tValidation-mlogloss:1.76800\n",
      "[2]\tValidation-mlogloss:1.75631\n",
      "[3]\tValidation-mlogloss:1.74472\n",
      "[4]\tValidation-mlogloss:1.73443\n",
      "[5]\tValidation-mlogloss:1.72340\n",
      "[6]\tValidation-mlogloss:1.71257\n",
      "[7]\tValidation-mlogloss:1.70279\n",
      "[8]\tValidation-mlogloss:1.69336\n",
      "[9]\tValidation-mlogloss:1.68379\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:38,591]\u001b[0m Trial 49 finished with value: 0.6045 and parameters: {'eta': 0.020271847216640125, 'max_depth': 8, 'min_child_weight': 3, 'subsample': 0.6793287509904017, 'colsample_bytree': 0.6762133916719317, 'alpha': 0.7580456018969164, 'lambda': 0.3797873092394687, 'gamma': 0.08161234038272036, 'n_estimators': 185}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.73285\n",
      "[1]\tValidation-mlogloss:1.67649\n",
      "[2]\tValidation-mlogloss:1.62801\n",
      "[3]\tValidation-mlogloss:1.58280\n",
      "[4]\tValidation-mlogloss:1.54173\n",
      "[5]\tValidation-mlogloss:1.50222\n",
      "[6]\tValidation-mlogloss:1.46712\n",
      "[7]\tValidation-mlogloss:1.43748\n",
      "[8]\tValidation-mlogloss:1.40827\n",
      "[9]\tValidation-mlogloss:1.38270\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:40,170]\u001b[0m Trial 50 finished with value: 0.7125 and parameters: {'eta': 0.09813362644550956, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.6441325203648729, 'colsample_bytree': 0.7671887936013358, 'alpha': 0.6286489014234538, 'lambda': 0.5644775492560903, 'gamma': 0.050361435209314964, 'n_estimators': 267}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67003\n",
      "[1]\tValidation-mlogloss:1.56337\n",
      "[2]\tValidation-mlogloss:1.47646\n",
      "[3]\tValidation-mlogloss:1.40419\n",
      "[4]\tValidation-mlogloss:1.34761\n",
      "[5]\tValidation-mlogloss:1.28955\n",
      "[6]\tValidation-mlogloss:1.24154\n",
      "[7]\tValidation-mlogloss:1.20499\n",
      "[8]\tValidation-mlogloss:1.16406\n",
      "[9]\tValidation-mlogloss:1.12950\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:41,241]\u001b[0m Trial 51 finished with value: 0.7785 and parameters: {'eta': 0.19725269871387463, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5378973012045648, 'colsample_bytree': 0.6180562528696188, 'alpha': 0.8141415890621562, 'lambda': 0.13680349793295093, 'gamma': 0.18376092811766984, 'n_estimators': 133}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70047\n",
      "[1]\tValidation-mlogloss:1.61769\n",
      "[2]\tValidation-mlogloss:1.54750\n",
      "[3]\tValidation-mlogloss:1.48533\n",
      "[4]\tValidation-mlogloss:1.43453\n",
      "[5]\tValidation-mlogloss:1.38447\n",
      "[6]\tValidation-mlogloss:1.34132\n",
      "[7]\tValidation-mlogloss:1.30446\n",
      "[8]\tValidation-mlogloss:1.26710\n",
      "[9]\tValidation-mlogloss:1.23545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:42,403]\u001b[0m Trial 52 finished with value: 0.7635 and parameters: {'eta': 0.14547332688312606, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.501610040302057, 'colsample_bytree': 0.6193984767087981, 'alpha': 0.8103344817575884, 'lambda': 0.04657453900411836, 'gamma': 0.24428592014098421, 'n_estimators': 139}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:42] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68367\n",
      "[1]\tValidation-mlogloss:1.59015\n",
      "[2]\tValidation-mlogloss:1.51459\n",
      "[3]\tValidation-mlogloss:1.44727\n",
      "[4]\tValidation-mlogloss:1.39218\n",
      "[5]\tValidation-mlogloss:1.34041\n",
      "[6]\tValidation-mlogloss:1.29484\n",
      "[7]\tValidation-mlogloss:1.25616\n",
      "[8]\tValidation-mlogloss:1.22203\n",
      "[9]\tValidation-mlogloss:1.18969\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:44,194]\u001b[0m Trial 53 finished with value: 0.753 and parameters: {'eta': 0.17984849698302785, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.5716546619783921, 'colsample_bytree': 0.6851953500977122, 'alpha': 0.8873647171582355, 'lambda': 0.18803226385022928, 'gamma': 0.17479492907134636, 'n_estimators': 204}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70378\n",
      "[1]\tValidation-mlogloss:1.62167\n",
      "[2]\tValidation-mlogloss:1.56147\n",
      "[3]\tValidation-mlogloss:1.50187\n",
      "[4]\tValidation-mlogloss:1.45534\n",
      "[5]\tValidation-mlogloss:1.41029\n",
      "[6]\tValidation-mlogloss:1.37390\n",
      "[7]\tValidation-mlogloss:1.34124\n",
      "[8]\tValidation-mlogloss:1.31175\n",
      "[9]\tValidation-mlogloss:1.28600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:46,121]\u001b[0m Trial 54 finished with value: 0.666 and parameters: {'eta': 0.1958268113128007, 'max_depth': 10, 'min_child_weight': 9, 'subsample': 0.5355626150221042, 'colsample_bytree': 0.5820865145150839, 'alpha': 0.8963523513236369, 'lambda': 0.13390278112439985, 'gamma': 0.180500337893913, 'n_estimators': 121}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69574\n",
      "[1]\tValidation-mlogloss:1.61215\n",
      "[2]\tValidation-mlogloss:1.54041\n",
      "[3]\tValidation-mlogloss:1.47890\n",
      "[4]\tValidation-mlogloss:1.42665\n",
      "[5]\tValidation-mlogloss:1.37787\n",
      "[6]\tValidation-mlogloss:1.33321\n",
      "[7]\tValidation-mlogloss:1.29796\n",
      "[8]\tValidation-mlogloss:1.26337\n",
      "[9]\tValidation-mlogloss:1.23259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:47,544]\u001b[0m Trial 55 finished with value: 0.739 and parameters: {'eta': 0.1583140416010556, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.5930364634083234, 'colsample_bytree': 0.661366570363654, 'alpha': 0.538423110797577, 'lambda': 0.2477875346061787, 'gamma': 0.10733618045570179, 'n_estimators': 199}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:47] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.74009\n",
      "[1]\tValidation-mlogloss:1.69354\n",
      "[2]\tValidation-mlogloss:1.65409\n",
      "[3]\tValidation-mlogloss:1.61583\n",
      "[4]\tValidation-mlogloss:1.58341\n",
      "[5]\tValidation-mlogloss:1.55145\n",
      "[6]\tValidation-mlogloss:1.52290\n",
      "[7]\tValidation-mlogloss:1.50025\n",
      "[8]\tValidation-mlogloss:1.47733\n",
      "[9]\tValidation-mlogloss:1.45556\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:48,293]\u001b[0m Trial 56 finished with value: 0.562 and parameters: {'eta': 0.11941502152492312, 'max_depth': 4, 'min_child_weight': 4, 'subsample': 0.6256410687717566, 'colsample_bytree': 0.7343478581183828, 'alpha': 0.7346766760635306, 'lambda': 0.367306789199736, 'gamma': 0.4354426589263568, 'n_estimators': 268}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71462\n",
      "[1]\tValidation-mlogloss:1.64271\n",
      "[2]\tValidation-mlogloss:1.58391\n",
      "[3]\tValidation-mlogloss:1.53165\n",
      "[4]\tValidation-mlogloss:1.48384\n",
      "[5]\tValidation-mlogloss:1.43806\n",
      "[6]\tValidation-mlogloss:1.39848\n",
      "[7]\tValidation-mlogloss:1.36640\n",
      "[8]\tValidation-mlogloss:1.33500\n",
      "[9]\tValidation-mlogloss:1.30550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:49,373]\u001b[0m Trial 57 finished with value: 0.732 and parameters: {'eta': 0.13480475850669427, 'max_depth': 8, 'min_child_weight': 2, 'subsample': 0.7074111836037058, 'colsample_bytree': 0.6256411846593439, 'alpha': 0.7913471061826749, 'lambda': 0.053805416367597794, 'gamma': 0.3433831747362506, 'n_estimators': 139}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:49] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68215\n",
      "[1]\tValidation-mlogloss:1.58466\n",
      "[2]\tValidation-mlogloss:1.50470\n",
      "[3]\tValidation-mlogloss:1.43900\n",
      "[4]\tValidation-mlogloss:1.38207\n",
      "[5]\tValidation-mlogloss:1.32713\n",
      "[6]\tValidation-mlogloss:1.27764\n",
      "[7]\tValidation-mlogloss:1.23713\n",
      "[8]\tValidation-mlogloss:1.19951\n",
      "[9]\tValidation-mlogloss:1.16714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:50,510]\u001b[0m Trial 58 finished with value: 0.78 and parameters: {'eta': 0.17581581506196794, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.5373363558032266, 'colsample_bytree': 0.6914071169851622, 'alpha': 0.8396090275368666, 'lambda': 0.19998290148127212, 'gamma': 0.02762976360011682, 'n_estimators': 353}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:50] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.75809\n",
      "[1]\tValidation-mlogloss:1.72491\n",
      "[2]\tValidation-mlogloss:1.69568\n",
      "[3]\tValidation-mlogloss:1.66592\n",
      "[4]\tValidation-mlogloss:1.64021\n",
      "[5]\tValidation-mlogloss:1.61352\n",
      "[6]\tValidation-mlogloss:1.58883\n",
      "[7]\tValidation-mlogloss:1.56740\n",
      "[8]\tValidation-mlogloss:1.54475\n",
      "[9]\tValidation-mlogloss:1.52418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:51,572]\u001b[0m Trial 59 finished with value: 0.6795 and parameters: {'eta': 0.052968794991516896, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5303841980249092, 'colsample_bytree': 0.6040517489863653, 'alpha': 0.9518588548562325, 'lambda': 0.10735714247785826, 'gamma': 0.26528655724857403, 'n_estimators': 357}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.72068\n",
      "[1]\tValidation-mlogloss:1.65622\n",
      "[2]\tValidation-mlogloss:1.60049\n",
      "[3]\tValidation-mlogloss:1.54691\n",
      "[4]\tValidation-mlogloss:1.50391\n",
      "[5]\tValidation-mlogloss:1.46043\n",
      "[6]\tValidation-mlogloss:1.42269\n",
      "[7]\tValidation-mlogloss:1.38937\n",
      "[8]\tValidation-mlogloss:1.35682\n",
      "[9]\tValidation-mlogloss:1.32469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:53,090]\u001b[0m Trial 60 finished with value: 0.75 and parameters: {'eta': 0.1099496782825817, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9564245446910153, 'colsample_bytree': 0.6611515619164701, 'alpha': 0.847180997345578, 'lambda': 0.19404379577960473, 'gamma': 0.21949954428375645, 'n_estimators': 500}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:53] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68939\n",
      "[1]\tValidation-mlogloss:1.59687\n",
      "[2]\tValidation-mlogloss:1.52236\n",
      "[3]\tValidation-mlogloss:1.45923\n",
      "[4]\tValidation-mlogloss:1.40242\n",
      "[5]\tValidation-mlogloss:1.34885\n",
      "[6]\tValidation-mlogloss:1.30561\n",
      "[7]\tValidation-mlogloss:1.26656\n",
      "[8]\tValidation-mlogloss:1.23197\n",
      "[9]\tValidation-mlogloss:1.20066\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:54,417]\u001b[0m Trial 61 finished with value: 0.7595 and parameters: {'eta': 0.17235070387352106, 'max_depth': 9, 'min_child_weight': 4, 'subsample': 0.5688712868035274, 'colsample_bytree': 0.716654012207721, 'alpha': 0.6976622198271059, 'lambda': 0.16144031781117146, 'gamma': 0.002236653351574115, 'n_estimators': 175}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:54] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69322\n",
      "[1]\tValidation-mlogloss:1.60599\n",
      "[2]\tValidation-mlogloss:1.53347\n",
      "[3]\tValidation-mlogloss:1.47073\n",
      "[4]\tValidation-mlogloss:1.41762\n",
      "[5]\tValidation-mlogloss:1.36714\n",
      "[6]\tValidation-mlogloss:1.32290\n",
      "[7]\tValidation-mlogloss:1.28396\n",
      "[8]\tValidation-mlogloss:1.25038\n",
      "[9]\tValidation-mlogloss:1.21708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:55,723]\u001b[0m Trial 62 finished with value: 0.77 and parameters: {'eta': 0.15361456973070847, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7644934628526245, 'colsample_bytree': 0.6822592598945083, 'alpha': 0.7495285597574489, 'lambda': 0.2353139305362241, 'gamma': 0.057213971651831314, 'n_estimators': 131}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:55] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68041\n",
      "[1]\tValidation-mlogloss:1.58210\n",
      "[2]\tValidation-mlogloss:1.50434\n",
      "[3]\tValidation-mlogloss:1.43492\n",
      "[4]\tValidation-mlogloss:1.37739\n",
      "[5]\tValidation-mlogloss:1.32217\n",
      "[6]\tValidation-mlogloss:1.27357\n",
      "[7]\tValidation-mlogloss:1.23604\n",
      "[8]\tValidation-mlogloss:1.19729\n",
      "[9]\tValidation-mlogloss:1.16378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:56,986]\u001b[0m Trial 63 finished with value: 0.764 and parameters: {'eta': 0.18375611410740686, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5498566035018905, 'colsample_bytree': 0.5571441051770708, 'alpha': 0.9100785949223289, 'lambda': 0.14179081295342996, 'gamma': 0.1525082647205725, 'n_estimators': 123}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:57] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69779\n",
      "[1]\tValidation-mlogloss:1.61468\n",
      "[2]\tValidation-mlogloss:1.54247\n",
      "[3]\tValidation-mlogloss:1.48112\n",
      "[4]\tValidation-mlogloss:1.42824\n",
      "[5]\tValidation-mlogloss:1.37921\n",
      "[6]\tValidation-mlogloss:1.33648\n",
      "[7]\tValidation-mlogloss:1.29720\n",
      "[8]\tValidation-mlogloss:1.26359\n",
      "[9]\tValidation-mlogloss:1.23219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:58,080]\u001b[0m Trial 64 finished with value: 0.7615 and parameters: {'eta': 0.15484521245973534, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.5299044109325471, 'colsample_bytree': 0.6927848573840858, 'alpha': 0.801610928014836, 'lambda': 0.05405111191190377, 'gamma': 0.031880569556222885, 'n_estimators': 202}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:58] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67941\n",
      "[1]\tValidation-mlogloss:1.58487\n",
      "[2]\tValidation-mlogloss:1.50499\n",
      "[3]\tValidation-mlogloss:1.43915\n",
      "[4]\tValidation-mlogloss:1.38263\n",
      "[5]\tValidation-mlogloss:1.32766\n",
      "[6]\tValidation-mlogloss:1.28091\n",
      "[7]\tValidation-mlogloss:1.24436\n",
      "[8]\tValidation-mlogloss:1.20768\n",
      "[9]\tValidation-mlogloss:1.17337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:23:59,352]\u001b[0m Trial 65 finished with value: 0.767 and parameters: {'eta': 0.17902013222879765, 'max_depth': 10, 'min_child_weight': 5, 'subsample': 0.5776104606021529, 'colsample_bytree': 0.6561771814856018, 'alpha': 0.8238835372167294, 'lambda': 0.4500608232390085, 'gamma': 0.09228908576587032, 'n_estimators': 326}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:23:59] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70972\n",
      "[1]\tValidation-mlogloss:1.63739\n",
      "[2]\tValidation-mlogloss:1.57332\n",
      "[3]\tValidation-mlogloss:1.51668\n",
      "[4]\tValidation-mlogloss:1.46886\n",
      "[5]\tValidation-mlogloss:1.42275\n",
      "[6]\tValidation-mlogloss:1.38103\n",
      "[7]\tValidation-mlogloss:1.34562\n",
      "[8]\tValidation-mlogloss:1.31068\n",
      "[9]\tValidation-mlogloss:1.28099\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:00,581]\u001b[0m Trial 66 finished with value: 0.735 and parameters: {'eta': 0.137554125316223, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.5987170031017015, 'colsample_bytree': 0.6280441998085267, 'alpha': 0.862222168941434, 'lambda': 0.2958000258475101, 'gamma': 0.8242667906132184, 'n_estimators': 262}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:00] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.76630\n",
      "[1]\tValidation-mlogloss:1.74070\n",
      "[2]\tValidation-mlogloss:1.71701\n",
      "[3]\tValidation-mlogloss:1.69405\n",
      "[4]\tValidation-mlogloss:1.67307\n",
      "[5]\tValidation-mlogloss:1.65180\n",
      "[6]\tValidation-mlogloss:1.63108\n",
      "[7]\tValidation-mlogloss:1.61298\n",
      "[8]\tValidation-mlogloss:1.59443\n",
      "[9]\tValidation-mlogloss:1.57694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:01,774]\u001b[0m Trial 67 finished with value: 0.6715 and parameters: {'eta': 0.04069672346224293, 'max_depth': 10, 'min_child_weight': 1, 'subsample': 0.5262813985588929, 'colsample_bytree': 0.5721842655588525, 'alpha': 0.9476458944323779, 'lambda': 0.0897429420539864, 'gamma': 0.20510529767749802, 'n_estimators': 429}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:01] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69402\n",
      "[1]\tValidation-mlogloss:1.60621\n",
      "[2]\tValidation-mlogloss:1.53631\n",
      "[3]\tValidation-mlogloss:1.47416\n",
      "[4]\tValidation-mlogloss:1.42290\n",
      "[5]\tValidation-mlogloss:1.37327\n",
      "[6]\tValidation-mlogloss:1.33104\n",
      "[7]\tValidation-mlogloss:1.29571\n",
      "[8]\tValidation-mlogloss:1.26026\n",
      "[9]\tValidation-mlogloss:1.22964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:02,695]\u001b[0m Trial 68 finished with value: 0.7095 and parameters: {'eta': 0.1877201022657586, 'max_depth': 7, 'min_child_weight': 1, 'subsample': 0.5470406626516113, 'colsample_bytree': 0.5278093772677703, 'alpha': 0.39267142983547, 'lambda': 0.1491624814508738, 'gamma': 0.16053978683818512, 'n_estimators': 157}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:02] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71644\n",
      "[1]\tValidation-mlogloss:1.64593\n",
      "[2]\tValidation-mlogloss:1.58567\n",
      "[3]\tValidation-mlogloss:1.53098\n",
      "[4]\tValidation-mlogloss:1.48549\n",
      "[5]\tValidation-mlogloss:1.43990\n",
      "[6]\tValidation-mlogloss:1.40117\n",
      "[7]\tValidation-mlogloss:1.36702\n",
      "[8]\tValidation-mlogloss:1.33236\n",
      "[9]\tValidation-mlogloss:1.30263\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:03,740]\u001b[0m Trial 69 finished with value: 0.7485 and parameters: {'eta': 0.1224292582205852, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.5011176204488681, 'colsample_bytree': 0.5991317992822157, 'alpha': 0.8944083167821492, 'lambda': 0.10981966771094942, 'gamma': 0.11700509456265891, 'n_estimators': 106}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:03] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.71488\n",
      "[1]\tValidation-mlogloss:1.64362\n",
      "[2]\tValidation-mlogloss:1.58623\n",
      "[3]\tValidation-mlogloss:1.53065\n",
      "[4]\tValidation-mlogloss:1.48556\n",
      "[5]\tValidation-mlogloss:1.44014\n",
      "[6]\tValidation-mlogloss:1.40080\n",
      "[7]\tValidation-mlogloss:1.37308\n",
      "[8]\tValidation-mlogloss:1.34243\n",
      "[9]\tValidation-mlogloss:1.31540\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:04,519]\u001b[0m Trial 70 finished with value: 0.6635 and parameters: {'eta': 0.16126095962862597, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.5656970162478259, 'colsample_bytree': 0.5135475969599592, 'alpha': 0.9750200019501428, 'lambda': 0.04251856789288255, 'gamma': 0.29077451378993324, 'n_estimators': 157}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:04] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.66369\n",
      "[1]\tValidation-mlogloss:1.55208\n",
      "[2]\tValidation-mlogloss:1.46598\n",
      "[3]\tValidation-mlogloss:1.39660\n",
      "[4]\tValidation-mlogloss:1.33475\n",
      "[5]\tValidation-mlogloss:1.27747\n",
      "[6]\tValidation-mlogloss:1.23122\n",
      "[7]\tValidation-mlogloss:1.19023\n",
      "[8]\tValidation-mlogloss:1.15459\n",
      "[9]\tValidation-mlogloss:1.12179\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:06,014]\u001b[0m Trial 71 finished with value: 0.7755 and parameters: {'eta': 0.1997089635700747, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7365187050132158, 'colsample_bytree': 0.7218973139322443, 'alpha': 0.7708710022046183, 'lambda': 0.2085959709202597, 'gamma': 0.030302405055616977, 'n_estimators': 214}. Best is trial 33 with value: 0.78.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:06] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.66769\n",
      "[1]\tValidation-mlogloss:1.55496\n",
      "[2]\tValidation-mlogloss:1.46746\n",
      "[3]\tValidation-mlogloss:1.39788\n",
      "[4]\tValidation-mlogloss:1.33697\n",
      "[5]\tValidation-mlogloss:1.28014\n",
      "[6]\tValidation-mlogloss:1.23416\n",
      "[7]\tValidation-mlogloss:1.19016\n",
      "[8]\tValidation-mlogloss:1.15351\n",
      "[9]\tValidation-mlogloss:1.11917\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:07,405]\u001b[0m Trial 72 finished with value: 0.7895 and parameters: {'eta': 0.19944274652416194, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7397282913181034, 'colsample_bytree': 0.7543721321626481, 'alpha': 0.7800073180511335, 'lambda': 0.20658476265925035, 'gamma': 0.06605584163457628, 'n_estimators': 216}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:07] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67051\n",
      "[1]\tValidation-mlogloss:1.55693\n",
      "[2]\tValidation-mlogloss:1.47082\n",
      "[3]\tValidation-mlogloss:1.39895\n",
      "[4]\tValidation-mlogloss:1.33687\n",
      "[5]\tValidation-mlogloss:1.27930\n",
      "[6]\tValidation-mlogloss:1.23338\n",
      "[7]\tValidation-mlogloss:1.19087\n",
      "[8]\tValidation-mlogloss:1.15501\n",
      "[9]\tValidation-mlogloss:1.12248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:08,916]\u001b[0m Trial 73 finished with value: 0.7855 and parameters: {'eta': 0.19630655539212097, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7064853330805115, 'colsample_bytree': 0.7940752299820515, 'alpha': 0.6653494309424526, 'lambda': 0.21581447491688646, 'gamma': 0.07589602657490647, 'n_estimators': 225}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:08] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68414\n",
      "[1]\tValidation-mlogloss:1.58463\n",
      "[2]\tValidation-mlogloss:1.50829\n",
      "[3]\tValidation-mlogloss:1.44267\n",
      "[4]\tValidation-mlogloss:1.38636\n",
      "[5]\tValidation-mlogloss:1.33201\n",
      "[6]\tValidation-mlogloss:1.28871\n",
      "[7]\tValidation-mlogloss:1.24675\n",
      "[8]\tValidation-mlogloss:1.21226\n",
      "[9]\tValidation-mlogloss:1.17960\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:10,421]\u001b[0m Trial 74 finished with value: 0.7775 and parameters: {'eta': 0.16821098762625275, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.743113911509201, 'colsample_bytree': 0.7780855222524373, 'alpha': 0.7857785235680618, 'lambda': 0.20231468166164576, 'gamma': 0.04148391787095895, 'n_estimators': 246}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:10] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.77146\n",
      "[1]\tValidation-mlogloss:1.75064\n",
      "[2]\tValidation-mlogloss:1.73165\n",
      "[3]\tValidation-mlogloss:1.71288\n",
      "[4]\tValidation-mlogloss:1.69523\n",
      "[5]\tValidation-mlogloss:1.67729\n",
      "[6]\tValidation-mlogloss:1.66004\n",
      "[7]\tValidation-mlogloss:1.64441\n",
      "[8]\tValidation-mlogloss:1.62977\n",
      "[9]\tValidation-mlogloss:1.61453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:11,876]\u001b[0m Trial 75 finished with value: 0.663 and parameters: {'eta': 0.030822602556352132, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7369898736258843, 'colsample_bytree': 0.8020987848468677, 'alpha': 0.6578397227925304, 'lambda': 0.2083395934510668, 'gamma': 0.0718994340340785, 'n_estimators': 223}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:11] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69782\n",
      "[1]\tValidation-mlogloss:1.61147\n",
      "[2]\tValidation-mlogloss:1.54296\n",
      "[3]\tValidation-mlogloss:1.48006\n",
      "[4]\tValidation-mlogloss:1.42725\n",
      "[5]\tValidation-mlogloss:1.37697\n",
      "[6]\tValidation-mlogloss:1.33385\n",
      "[7]\tValidation-mlogloss:1.29172\n",
      "[8]\tValidation-mlogloss:1.25923\n",
      "[9]\tValidation-mlogloss:1.22715\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:13,406]\u001b[0m Trial 76 finished with value: 0.773 and parameters: {'eta': 0.14468401611098314, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.7816218978496889, 'colsample_bytree': 0.8230184647012323, 'alpha': 0.6842314710648072, 'lambda': 0.27950924920900533, 'gamma': 0.0426084741483819, 'n_estimators': 249}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:13] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.66927\n",
      "[1]\tValidation-mlogloss:1.55856\n",
      "[2]\tValidation-mlogloss:1.47277\n",
      "[3]\tValidation-mlogloss:1.39808\n",
      "[4]\tValidation-mlogloss:1.33777\n",
      "[5]\tValidation-mlogloss:1.27798\n",
      "[6]\tValidation-mlogloss:1.23179\n",
      "[7]\tValidation-mlogloss:1.19087\n",
      "[8]\tValidation-mlogloss:1.15503\n",
      "[9]\tValidation-mlogloss:1.12112\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:14,945]\u001b[0m Trial 77 finished with value: 0.786 and parameters: {'eta': 0.1996915421793793, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.7173578992280839, 'colsample_bytree': 0.7698933985569264, 'alpha': 0.7847789380221437, 'lambda': 0.2708931246955074, 'gamma': 0.03547711760638459, 'n_estimators': 388}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:14] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.75003\n",
      "[1]\tValidation-mlogloss:1.71035\n",
      "[2]\tValidation-mlogloss:1.67617\n",
      "[3]\tValidation-mlogloss:1.64310\n",
      "[4]\tValidation-mlogloss:1.61482\n",
      "[5]\tValidation-mlogloss:1.58633\n",
      "[6]\tValidation-mlogloss:1.55990\n",
      "[7]\tValidation-mlogloss:1.53737\n",
      "[8]\tValidation-mlogloss:1.51620\n",
      "[9]\tValidation-mlogloss:1.49541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:15,741]\u001b[0m Trial 78 finished with value: 0.5875 and parameters: {'eta': 0.08739105097929177, 'max_depth': 5, 'min_child_weight': 4, 'subsample': 0.7171067319907164, 'colsample_bytree': 0.763250483627469, 'alpha': 0.730879263530797, 'lambda': 0.2500119011763262, 'gamma': 0.08307163397345538, 'n_estimators': 289}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:15] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69361\n",
      "[1]\tValidation-mlogloss:1.60115\n",
      "[2]\tValidation-mlogloss:1.53226\n",
      "[3]\tValidation-mlogloss:1.46890\n",
      "[4]\tValidation-mlogloss:1.41330\n",
      "[5]\tValidation-mlogloss:1.36294\n",
      "[6]\tValidation-mlogloss:1.32254\n",
      "[7]\tValidation-mlogloss:1.28419\n",
      "[8]\tValidation-mlogloss:1.25082\n",
      "[9]\tValidation-mlogloss:1.21855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:17,037]\u001b[0m Trial 79 finished with value: 0.7645 and parameters: {'eta': 0.1622734080139715, 'max_depth': 9, 'min_child_weight': 7, 'subsample': 0.7539828115199938, 'colsample_bytree': 0.7854978132375233, 'alpha': 0.6147065330493314, 'lambda': 0.2643044516401817, 'gamma': 0.10475748997935258, 'n_estimators': 412}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:17] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67816\n",
      "[1]\tValidation-mlogloss:1.57513\n",
      "[2]\tValidation-mlogloss:1.49367\n",
      "[3]\tValidation-mlogloss:1.42493\n",
      "[4]\tValidation-mlogloss:1.36476\n",
      "[5]\tValidation-mlogloss:1.30918\n",
      "[6]\tValidation-mlogloss:1.26241\n",
      "[7]\tValidation-mlogloss:1.22269\n",
      "[8]\tValidation-mlogloss:1.18858\n",
      "[9]\tValidation-mlogloss:1.15581\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:18,620]\u001b[0m Trial 80 finished with value: 0.7825 and parameters: {'eta': 0.1799524452130222, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.806668670614868, 'colsample_bytree': 0.7970377632425033, 'alpha': 0.7861457991505977, 'lambda': 0.3474341063021874, 'gamma': 0.6250902859762674, 'n_estimators': 362}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:18] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68180\n",
      "[1]\tValidation-mlogloss:1.58200\n",
      "[2]\tValidation-mlogloss:1.50335\n",
      "[3]\tValidation-mlogloss:1.43549\n",
      "[4]\tValidation-mlogloss:1.37781\n",
      "[5]\tValidation-mlogloss:1.32225\n",
      "[6]\tValidation-mlogloss:1.27632\n",
      "[7]\tValidation-mlogloss:1.23482\n",
      "[8]\tValidation-mlogloss:1.19615\n",
      "[9]\tValidation-mlogloss:1.16387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:20,255]\u001b[0m Trial 81 finished with value: 0.7875 and parameters: {'eta': 0.17741291123010006, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.692394208770536, 'colsample_bytree': 0.7448836142055386, 'alpha': 0.7943192744054476, 'lambda': 0.34078758724275904, 'gamma': 0.6009932527928185, 'n_estimators': 398}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:20] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68022\n",
      "[1]\tValidation-mlogloss:1.57744\n",
      "[2]\tValidation-mlogloss:1.49507\n",
      "[3]\tValidation-mlogloss:1.42876\n",
      "[4]\tValidation-mlogloss:1.37143\n",
      "[5]\tValidation-mlogloss:1.31492\n",
      "[6]\tValidation-mlogloss:1.26846\n",
      "[7]\tValidation-mlogloss:1.23007\n",
      "[8]\tValidation-mlogloss:1.19395\n",
      "[9]\tValidation-mlogloss:1.16123\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:21,798]\u001b[0m Trial 82 finished with value: 0.782 and parameters: {'eta': 0.17821406173187623, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8069320232517163, 'colsample_bytree': 0.7520878583552285, 'alpha': 0.8168109382379913, 'lambda': 0.22771879858051527, 'gamma': 0.6647696483346659, 'n_estimators': 385}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:21] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67467\n",
      "[1]\tValidation-mlogloss:1.56790\n",
      "[2]\tValidation-mlogloss:1.48574\n",
      "[3]\tValidation-mlogloss:1.41649\n",
      "[4]\tValidation-mlogloss:1.35545\n",
      "[5]\tValidation-mlogloss:1.29751\n",
      "[6]\tValidation-mlogloss:1.25213\n",
      "[7]\tValidation-mlogloss:1.21151\n",
      "[8]\tValidation-mlogloss:1.17676\n",
      "[9]\tValidation-mlogloss:1.14393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:23,366]\u001b[0m Trial 83 finished with value: 0.7895 and parameters: {'eta': 0.1858215138496879, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.808868422264305, 'colsample_bytree': 0.7988503926495186, 'alpha': 0.8250885760469598, 'lambda': 0.336689917569191, 'gamma': 0.598729971738327, 'n_estimators': 390}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:23] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68077\n",
      "[1]\tValidation-mlogloss:1.57684\n",
      "[2]\tValidation-mlogloss:1.49529\n",
      "[3]\tValidation-mlogloss:1.42833\n",
      "[4]\tValidation-mlogloss:1.37126\n",
      "[5]\tValidation-mlogloss:1.31511\n",
      "[6]\tValidation-mlogloss:1.26895\n",
      "[7]\tValidation-mlogloss:1.22818\n",
      "[8]\tValidation-mlogloss:1.19296\n",
      "[9]\tValidation-mlogloss:1.15947\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:25,005]\u001b[0m Trial 84 finished with value: 0.7865 and parameters: {'eta': 0.1793851151255939, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8161653245603462, 'colsample_bytree': 0.7568636425561196, 'alpha': 0.8534320639852212, 'lambda': 0.35196904603656626, 'gamma': 0.6340345479402143, 'n_estimators': 379}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:25] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69694\n",
      "[1]\tValidation-mlogloss:1.60723\n",
      "[2]\tValidation-mlogloss:1.53588\n",
      "[3]\tValidation-mlogloss:1.47354\n",
      "[4]\tValidation-mlogloss:1.42131\n",
      "[5]\tValidation-mlogloss:1.37084\n",
      "[6]\tValidation-mlogloss:1.32819\n",
      "[7]\tValidation-mlogloss:1.28862\n",
      "[8]\tValidation-mlogloss:1.25424\n",
      "[9]\tValidation-mlogloss:1.22189\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:26,593]\u001b[0m Trial 85 finished with value: 0.781 and parameters: {'eta': 0.15094454955003278, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8085467103693379, 'colsample_bytree': 0.753024266729308, 'alpha': 0.8541733296653822, 'lambda': 0.33765787462212404, 'gamma': 0.6073002815298926, 'n_estimators': 370}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:26] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69613\n",
      "[1]\tValidation-mlogloss:1.60580\n",
      "[2]\tValidation-mlogloss:1.53402\n",
      "[3]\tValidation-mlogloss:1.47133\n",
      "[4]\tValidation-mlogloss:1.41898\n",
      "[5]\tValidation-mlogloss:1.36802\n",
      "[6]\tValidation-mlogloss:1.32441\n",
      "[7]\tValidation-mlogloss:1.28420\n",
      "[8]\tValidation-mlogloss:1.25038\n",
      "[9]\tValidation-mlogloss:1.21766\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:28,348]\u001b[0m Trial 86 finished with value: 0.783 and parameters: {'eta': 0.1524416146307226, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8109186425424199, 'colsample_bytree': 0.7464409351237397, 'alpha': 0.8631662798568485, 'lambda': 0.34969864783013177, 'gamma': 0.6190392188242697, 'n_estimators': 443}. Best is trial 72 with value: 0.7895.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:28] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67715\n",
      "[1]\tValidation-mlogloss:1.57221\n",
      "[2]\tValidation-mlogloss:1.49175\n",
      "[3]\tValidation-mlogloss:1.42126\n",
      "[4]\tValidation-mlogloss:1.35948\n",
      "[5]\tValidation-mlogloss:1.30400\n",
      "[6]\tValidation-mlogloss:1.25934\n",
      "[7]\tValidation-mlogloss:1.21695\n",
      "[8]\tValidation-mlogloss:1.18122\n",
      "[9]\tValidation-mlogloss:1.14832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:30,000]\u001b[0m Trial 87 finished with value: 0.7915 and parameters: {'eta': 0.18296109456309345, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8358322522103684, 'colsample_bytree': 0.7988109190340285, 'alpha': 0.7848792555804489, 'lambda': 0.4317447755193065, 'gamma': 0.6827952855725711, 'n_estimators': 472}. Best is trial 87 with value: 0.7915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:30] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.78510\n",
      "[1]\tValidation-mlogloss:1.77812\n",
      "[2]\tValidation-mlogloss:1.77149\n",
      "[3]\tValidation-mlogloss:1.76482\n",
      "[4]\tValidation-mlogloss:1.75847\n",
      "[5]\tValidation-mlogloss:1.75196\n",
      "[6]\tValidation-mlogloss:1.74560\n",
      "[7]\tValidation-mlogloss:1.73965\n",
      "[8]\tValidation-mlogloss:1.73389\n",
      "[9]\tValidation-mlogloss:1.72800\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:31,556]\u001b[0m Trial 88 finished with value: 0.62 and parameters: {'eta': 0.010042664495111462, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8299730563799631, 'colsample_bytree': 0.7970507425013135, 'alpha': 0.7500905222373223, 'lambda': 0.43945226185247466, 'gamma': 0.5657959681976298, 'n_estimators': 467}. Best is trial 87 with value: 0.7915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:31] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.74888\n",
      "[1]\tValidation-mlogloss:1.70839\n",
      "[2]\tValidation-mlogloss:1.67204\n",
      "[3]\tValidation-mlogloss:1.63820\n",
      "[4]\tValidation-mlogloss:1.60624\n",
      "[5]\tValidation-mlogloss:1.57509\n",
      "[6]\tValidation-mlogloss:1.54608\n",
      "[7]\tValidation-mlogloss:1.52061\n",
      "[8]\tValidation-mlogloss:1.49680\n",
      "[9]\tValidation-mlogloss:1.47252\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:33,018]\u001b[0m Trial 89 finished with value: 0.6895 and parameters: {'eta': 0.0672178444630713, 'max_depth': 9, 'min_child_weight': 2, 'subsample': 0.7878130742435971, 'colsample_bytree': 0.8507185563917157, 'alpha': 0.7748266045957901, 'lambda': 0.36204929234748384, 'gamma': 0.6887421851970551, 'n_estimators': 545}. Best is trial 87 with value: 0.7915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:33] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70902\n",
      "[1]\tValidation-mlogloss:1.63132\n",
      "[2]\tValidation-mlogloss:1.57087\n",
      "[3]\tValidation-mlogloss:1.51179\n",
      "[4]\tValidation-mlogloss:1.46130\n",
      "[5]\tValidation-mlogloss:1.41323\n",
      "[6]\tValidation-mlogloss:1.37395\n",
      "[7]\tValidation-mlogloss:1.33691\n",
      "[8]\tValidation-mlogloss:1.30375\n",
      "[9]\tValidation-mlogloss:1.27418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:34,945]\u001b[0m Trial 90 finished with value: 0.7605 and parameters: {'eta': 0.12803920276753175, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8481603765857483, 'colsample_bytree': 0.8012627826011339, 'alpha': 0.7301907355044239, 'lambda': 0.41233218367187385, 'gamma': 0.6142615591227042, 'n_estimators': 501}. Best is trial 87 with value: 0.7915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:34] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67516\n",
      "[1]\tValidation-mlogloss:1.57229\n",
      "[2]\tValidation-mlogloss:1.48996\n",
      "[3]\tValidation-mlogloss:1.42291\n",
      "[4]\tValidation-mlogloss:1.36051\n",
      "[5]\tValidation-mlogloss:1.30374\n",
      "[6]\tValidation-mlogloss:1.25734\n",
      "[7]\tValidation-mlogloss:1.21612\n",
      "[8]\tValidation-mlogloss:1.18109\n",
      "[9]\tValidation-mlogloss:1.14743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:36,636]\u001b[0m Trial 91 finished with value: 0.788 and parameters: {'eta': 0.1833351688716074, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8762335232177298, 'colsample_bytree': 0.8163627563494721, 'alpha': 0.8183257010241929, 'lambda': 0.3521176365593042, 'gamma': 0.6626098214385299, 'n_estimators': 406}. Best is trial 87 with value: 0.7915.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:36] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67638\n",
      "[1]\tValidation-mlogloss:1.57239\n",
      "[2]\tValidation-mlogloss:1.49029\n",
      "[3]\tValidation-mlogloss:1.42067\n",
      "[4]\tValidation-mlogloss:1.35908\n",
      "[5]\tValidation-mlogloss:1.30422\n",
      "[6]\tValidation-mlogloss:1.25740\n",
      "[7]\tValidation-mlogloss:1.21554\n",
      "[8]\tValidation-mlogloss:1.17894\n",
      "[9]\tValidation-mlogloss:1.14501\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:38,442]\u001b[0m Trial 92 finished with value: 0.7935 and parameters: {'eta': 0.18311815834114556, 'max_depth': 10, 'min_child_weight': 2, 'subsample': 0.8854962630911081, 'colsample_bytree': 0.8200609975391667, 'alpha': 0.7929299733753726, 'lambda': 0.3500939829630901, 'gamma': 0.5157937182820457, 'n_estimators': 448}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:38] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.69103\n",
      "[1]\tValidation-mlogloss:1.59908\n",
      "[2]\tValidation-mlogloss:1.52607\n",
      "[3]\tValidation-mlogloss:1.46052\n",
      "[4]\tValidation-mlogloss:1.40078\n",
      "[5]\tValidation-mlogloss:1.34884\n",
      "[6]\tValidation-mlogloss:1.30475\n",
      "[7]\tValidation-mlogloss:1.26442\n",
      "[8]\tValidation-mlogloss:1.23119\n",
      "[9]\tValidation-mlogloss:1.19853\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:40,049]\u001b[0m Trial 93 finished with value: 0.786 and parameters: {'eta': 0.15949922652153467, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8824440317810952, 'colsample_bytree': 0.8146920831816002, 'alpha': 0.6988130878528662, 'lambda': 0.5236888089873248, 'gamma': 0.5220279695616872, 'n_estimators': 435}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:40] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67616\n",
      "[1]\tValidation-mlogloss:1.57240\n",
      "[2]\tValidation-mlogloss:1.49125\n",
      "[3]\tValidation-mlogloss:1.42128\n",
      "[4]\tValidation-mlogloss:1.35927\n",
      "[5]\tValidation-mlogloss:1.30423\n",
      "[6]\tValidation-mlogloss:1.25663\n",
      "[7]\tValidation-mlogloss:1.21465\n",
      "[8]\tValidation-mlogloss:1.18007\n",
      "[9]\tValidation-mlogloss:1.14477\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:41,718]\u001b[0m Trial 94 finished with value: 0.793 and parameters: {'eta': 0.18496536667358351, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8862943749287524, 'colsample_bytree': 0.8182641760132128, 'alpha': 0.7037393825580482, 'lambda': 0.5625760731312192, 'gamma': 0.5344726901515582, 'n_estimators': 398}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:41] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.70479\n",
      "[1]\tValidation-mlogloss:1.62344\n",
      "[2]\tValidation-mlogloss:1.55652\n",
      "[3]\tValidation-mlogloss:1.49710\n",
      "[4]\tValidation-mlogloss:1.44389\n",
      "[5]\tValidation-mlogloss:1.39562\n",
      "[6]\tValidation-mlogloss:1.35466\n",
      "[7]\tValidation-mlogloss:1.31393\n",
      "[8]\tValidation-mlogloss:1.28187\n",
      "[9]\tValidation-mlogloss:1.24962\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:43,324]\u001b[0m Trial 95 finished with value: 0.773 and parameters: {'eta': 0.13683409785072612, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8864616968319458, 'colsample_bytree': 0.8144672480783629, 'alpha': 0.714866130941141, 'lambda': 0.5212965062204178, 'gamma': 0.49899793368837897, 'n_estimators': 404}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:43] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.75575\n",
      "[1]\tValidation-mlogloss:1.72098\n",
      "[2]\tValidation-mlogloss:1.68845\n",
      "[3]\tValidation-mlogloss:1.65882\n",
      "[4]\tValidation-mlogloss:1.63039\n",
      "[5]\tValidation-mlogloss:1.60183\n",
      "[6]\tValidation-mlogloss:1.57682\n",
      "[7]\tValidation-mlogloss:1.55275\n",
      "[8]\tValidation-mlogloss:1.53074\n",
      "[9]\tValidation-mlogloss:1.50823\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:44,829]\u001b[0m Trial 96 finished with value: 0.688 and parameters: {'eta': 0.05822927963377074, 'max_depth': 9, 'min_child_weight': 3, 'subsample': 0.91219987296959, 'colsample_bytree': 0.8326725270967336, 'alpha': 0.7017470623210915, 'lambda': 0.6155957161760454, 'gamma': 0.5409092036234869, 'n_estimators': 521}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:44] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.68547\n",
      "[1]\tValidation-mlogloss:1.59191\n",
      "[2]\tValidation-mlogloss:1.51734\n",
      "[3]\tValidation-mlogloss:1.45223\n",
      "[4]\tValidation-mlogloss:1.39156\n",
      "[5]\tValidation-mlogloss:1.34022\n",
      "[6]\tValidation-mlogloss:1.29589\n",
      "[7]\tValidation-mlogloss:1.25524\n",
      "[8]\tValidation-mlogloss:1.22119\n",
      "[9]\tValidation-mlogloss:1.18889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:46,542]\u001b[0m Trial 97 finished with value: 0.7765 and parameters: {'eta': 0.16455332768684877, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.8746544979294126, 'colsample_bytree': 0.8493523338455552, 'alpha': 0.826134230538506, 'lambda': 0.4994774557820713, 'gamma': 0.4687945136588618, 'n_estimators': 446}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:46] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67428\n",
      "[1]\tValidation-mlogloss:1.56881\n",
      "[2]\tValidation-mlogloss:1.48637\n",
      "[3]\tValidation-mlogloss:1.41746\n",
      "[4]\tValidation-mlogloss:1.35468\n",
      "[5]\tValidation-mlogloss:1.30053\n",
      "[6]\tValidation-mlogloss:1.25485\n",
      "[7]\tValidation-mlogloss:1.21027\n",
      "[8]\tValidation-mlogloss:1.17551\n",
      "[9]\tValidation-mlogloss:1.14160\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:48,554]\u001b[0m Trial 98 finished with value: 0.793 and parameters: {'eta': 0.18592004614309085, 'max_depth': 10, 'min_child_weight': 3, 'subsample': 0.9077345479023187, 'colsample_bytree': 0.8769393471678539, 'alpha': 0.6408498674331734, 'lambda': 0.5623911842099945, 'gamma': 0.7322656117643389, 'n_estimators': 589}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[16:24:48] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67511\n",
      "[1]\tValidation-mlogloss:1.57110\n",
      "[2]\tValidation-mlogloss:1.49217\n",
      "[3]\tValidation-mlogloss:1.42038\n",
      "[4]\tValidation-mlogloss:1.35885\n",
      "[5]\tValidation-mlogloss:1.30424\n",
      "[6]\tValidation-mlogloss:1.25828\n",
      "[7]\tValidation-mlogloss:1.21524\n",
      "[8]\tValidation-mlogloss:1.17957\n",
      "[9]\tValidation-mlogloss:1.14484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2023-02-10 16:24:50,278]\u001b[0m Trial 99 finished with value: 0.79 and parameters: {'eta': 0.18639104315184182, 'max_depth': 10, 'min_child_weight': 4, 'subsample': 0.9124549714566171, 'colsample_bytree': 0.7690920713961779, 'alpha': 0.6336629364575436, 'lambda': 0.6424395962165838, 'gamma': 0.7254694025947951, 'n_estimators': 614}. Best is trial 92 with value: 0.7935.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of finished trials: 100\n",
      "Best trial:\n",
      "  Value: 0.7935\n",
      "  Params: \n",
      "    eta: 0.18311815834114556\n",
      "    max_depth: 10\n",
      "    min_child_weight: 2\n",
      "    subsample: 0.8854962630911081\n",
      "    colsample_bytree: 0.8200609975391667\n",
      "    alpha: 0.7929299733753726\n",
      "    lambda: 0.3500939829630901\n",
      "    gamma: 0.5157937182820457\n",
      "    n_estimators: 448\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "\n",
    "    params = {\n",
    "        'objective': 'multi:softmax',\n",
    "        'num_class': 6,\n",
    "        'eval_metric': 'mlogloss',\n",
    "        'eta': trial.suggest_float('eta', 0.01, 0.2, log=True),\n",
    "        'max_depth': trial.suggest_int('max_depth', 3, 10),\n",
    "        'min_child_weight': trial.suggest_int('min_child_weight', 1, 10),\n",
    "        'subsample': trial.suggest_float('subsample', 0.5, 1.0),\n",
    "        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.5, 1.0),\n",
    "        'alpha': trial.suggest_float('alpha', 0.0, 1.0),\n",
    "        'lambda': trial.suggest_float('lambda', 0.0, 1.0),\n",
    "        'gamma': trial.suggest_float('gamma', 0.0, 1.0),\n",
    "        'n_estimators': trial.suggest_int('n_estimators', 100, 1000),        \n",
    "    }\n",
    "\n",
    "    optuna = xgb.train(params, train_data_dmatrix, num_boost_round=10, evals=[(val_data_dmatrix, \"Validation\")])\n",
    "\n",
    "    preds = optuna.predict(val_data_dmatrix)\n",
    "    pred_labels = np.rint(preds)\n",
    "    accuracy = accuracy_score(val_data['label'], pred_labels)\n",
    "\n",
    "    return accuracy\n",
    "    \n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=100)\n",
    "\n",
    "print('Number of finished trials: {}'.format(len(study.trials)))\n",
    "print('Best trial:')\n",
    "trial = study.best_trial\n",
    "\n",
    "print('  Value: {}'.format(trial.value))\n",
    "print('  Params: ')\n",
    "\n",
    "for key, value in trial.params.items():\n",
    "    print('    {}: {}'.format(key, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = trial.params\n",
    "params['objective'] = 'multi:softmax'\n",
    "params['num_class'] = 6\n",
    "params['eval_metric'] = 'mlogloss'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[17:03:51] WARNING: C:/Users/administrator/workspace/xgboost-win64_release_1.6.0/src/learner.cc:627: \n",
      "Parameters: { \"n_estimators\" } might not be used.\n",
      "\n",
      "  This could be a false alarm, with some parameters getting used by language bindings but\n",
      "  then being mistakenly passed down to XGBoost core, or some parameter actually being used\n",
      "  but getting flagged wrongly here. Please open an issue if you find any such cases.\n",
      "\n",
      "\n",
      "[0]\tValidation-mlogloss:1.67638\n",
      "[1]\tValidation-mlogloss:1.57239\n",
      "[2]\tValidation-mlogloss:1.49029\n",
      "[3]\tValidation-mlogloss:1.42067\n",
      "[4]\tValidation-mlogloss:1.35908\n",
      "[5]\tValidation-mlogloss:1.30422\n",
      "[6]\tValidation-mlogloss:1.25740\n",
      "[7]\tValidation-mlogloss:1.21554\n",
      "[8]\tValidation-mlogloss:1.17894\n",
      "[9]\tValidation-mlogloss:1.14501\n",
      "[10]\tValidation-mlogloss:1.11265\n",
      "[11]\tValidation-mlogloss:1.08432\n",
      "[12]\tValidation-mlogloss:1.05657\n",
      "[13]\tValidation-mlogloss:1.03083\n",
      "[14]\tValidation-mlogloss:1.00871\n",
      "[15]\tValidation-mlogloss:0.98754\n",
      "[16]\tValidation-mlogloss:0.96629\n",
      "[17]\tValidation-mlogloss:0.94684\n",
      "[18]\tValidation-mlogloss:0.92914\n",
      "[19]\tValidation-mlogloss:0.91113\n",
      "[20]\tValidation-mlogloss:0.89479\n",
      "[21]\tValidation-mlogloss:0.87894\n",
      "[22]\tValidation-mlogloss:0.86361\n",
      "[23]\tValidation-mlogloss:0.85031\n",
      "[24]\tValidation-mlogloss:0.83597\n",
      "[25]\tValidation-mlogloss:0.82392\n",
      "[26]\tValidation-mlogloss:0.81159\n",
      "[27]\tValidation-mlogloss:0.79947\n",
      "[28]\tValidation-mlogloss:0.78719\n",
      "[29]\tValidation-mlogloss:0.77664\n",
      "[30]\tValidation-mlogloss:0.76738\n",
      "[31]\tValidation-mlogloss:0.75667\n",
      "[32]\tValidation-mlogloss:0.74786\n",
      "[33]\tValidation-mlogloss:0.73756\n",
      "[34]\tValidation-mlogloss:0.72798\n",
      "[35]\tValidation-mlogloss:0.71891\n",
      "[36]\tValidation-mlogloss:0.71122\n",
      "[37]\tValidation-mlogloss:0.70353\n",
      "[38]\tValidation-mlogloss:0.69526\n",
      "[39]\tValidation-mlogloss:0.68727\n",
      "[40]\tValidation-mlogloss:0.68018\n",
      "[41]\tValidation-mlogloss:0.67373\n",
      "[42]\tValidation-mlogloss:0.66729\n",
      "[43]\tValidation-mlogloss:0.66115\n",
      "[44]\tValidation-mlogloss:0.65445\n",
      "[45]\tValidation-mlogloss:0.64670\n",
      "[46]\tValidation-mlogloss:0.64051\n",
      "[47]\tValidation-mlogloss:0.63388\n",
      "[48]\tValidation-mlogloss:0.62876\n",
      "[49]\tValidation-mlogloss:0.62252\n"
     ]
    }
   ],
   "source": [
    "classifier = xgb.train(params, train_data_dmatrix, num_boost_round=50, evals=[(val_data_dmatrix, \"Validation\")] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = classifier.predict(test_data_dmatrix)\n",
    "y_pred = np.rint(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_values(['anger', 'fear', 'joy', 'love', 'sadness', 'surprise'])\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.90      0.84      0.87       275\n",
      "        fear       0.86      0.84      0.85       224\n",
      "         joy       0.86      0.92      0.89       695\n",
      "        love       0.74      0.79      0.76       159\n",
      "     sadness       0.95      0.90      0.92       581\n",
      "    surprise       0.65      0.70      0.67        66\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.83      0.83      0.83      2000\n",
      "weighted avg       0.88      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "label_decoding = {val: key for key, val in labels_encoding.items()}\n",
    "print(classification_report(test_data['label'], y_pred, target_names=label_decoding.values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.heatmap(confusion_matrix(test_data['label'], y_pred), annot=True, fmt='d', xticklabels=label_decoding.values(), yticklabels=label_decoding.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.11"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "f1fb958e2eb6def37cd852490dd556386865bd239fc7fb3d2ffb35ec0d2f3844"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
